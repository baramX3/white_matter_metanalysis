{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os.path as op\n",
    "import os\n",
    "import glob # imported for csv\n",
    "import gc\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "from gradec.decode import LDADecoder\n",
    "from gradec.utils import _rm_medial_wall, _decoding_filter\n",
    "from gradec.plot import plot_surf_maps, plot_radar, plot_cloud\n",
    "from gradec.fetcher import _fetch_features, _fetch_frequencies, _fetch_classification\n",
    "import nibabel as nib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create csv file with all tract names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_dir = os.getcwd() + \"/data/white-matter-atlas_thresholds/cortexmap_binarize_smooth-surf-1_threshold-0.15_dilate-0/cortexmap/func\"\n",
    "file_names = []\n",
    "for x in os.listdir(file_dir):\n",
    "    if x.endswith(\".gii\"):\n",
    "        file_names.append(x)\n",
    "\n",
    "regions_bi = []\n",
    "regions_mono = []\n",
    "\n",
    "for i in file_names:\n",
    "    split_region = i.split(\"_\")[0][3:]\n",
    "    if split_region.find('left') == 0:\n",
    "        regions_bi.append(split_region[4:])\n",
    "    elif split_region.find('right') == 0:\n",
    "        regions_bi.append(split_region[5:])\n",
    "    else:\n",
    "        regions_mono.append(split_region)\n",
    "\n",
    "#np.array(regions_mono).tofile(\"regions_mono.csv\", sep = \",\")\n",
    "#np.array(regions_bi).tofile(\"regions_bi.csv\", sep = \",\")\n",
    "\n",
    "sub = sorted(list(set(regions_bi)))\n",
    "len(sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define space, density and paths to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPACE, DENSITY = \"fsaverage\", \"164k\"\n",
    "DSET, MODEL = \"neuroquery\", \"lda\"\n",
    "\n",
    "data_dir = op.join(\".\", \"data\")\n",
    "neuromaps_dir = op.join(data_dir, \"neuromaps\")\n",
    "figures_dir = op.join(data_dir, \"figures\")\n",
    "\n",
    "# List of possible combinations of tracts, regions and smoothing\n",
    "#tracts = [\"Arc\", \"SLF1And2\", \"CST\"]\n",
    "tracts = sub\n",
    "regions = [\"RAS\", \"LPI\"]\n",
    "smths = [\"\", \".smooth_1\"]\n",
    "thresholds = [\"0\", \"0.15\", \"0.25\"]\n",
    "\n",
    "# Dictionaries for the title of the figures\n",
    "\"\"\" TRACTS_DICT = {\n",
    "    \"Arc\": \"Arcuate\",\n",
    "    \"CST\": \"Corticospinal\",\n",
    "    \"SLF1And2\": \"SLF 1 & 2\",\n",
    "    \"forcepsMajor\": \"Forceps Major\",\n",
    "} \"\"\"\n",
    "TRACTS_DICT = dict(zip(regions_bi, regions_bi))\n",
    "REGIONS_DICT = {\n",
    "    \"LPI\": \"Left-Posterior-Inferior\",\n",
    "    \"RAS\": \"Right-Anterior-Superior\",\n",
    "}\n",
    "SMTHS_DICT = {\n",
    "    \"\": \"Unsmoothed\",\n",
    "    \".smooth_1\": \"Smoothed\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and LDA-based decoder on NeuroQuery detabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode = LDADecoder(space=SPACE, density=DENSITY, calc_pvals=False, data_dir=data_dir)\n",
    "decode.fit(DSET)\n",
    "\n",
    "# Load features for visualization\n",
    "features = _fetch_features(DSET, MODEL, data_dir=data_dir)\n",
    "frequencies = _fetch_frequencies(DSET, MODEL, data_dir=data_dir)\n",
    "classification, class_lst = _fetch_classification(DSET, MODEL, data_dir=data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### @Daniela HERE's YOUR RESOURCE: Run decoder on each regions separate to output correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IF only wanting to a few figures\n",
    "tracts = [\"ILF\"]\n",
    "regions = [\"LPI\"]\n",
    "smths = [\".smooth_1\"]\n",
    "thresholds = [\"0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "# RADAR PLOTS AND CORRELATION VALUESs\n",
    "sep_figures_dir_test = op.join(figures_dir, \"separated_test\")\n",
    "os.makedirs(sep_figures_dir_test, exist_ok=True)\n",
    "\n",
    "separated_results = {}\n",
    "corrs_all = []\n",
    "features_all = []\n",
    "fileName = []\n",
    "for fig_i, (threshold, tract, region, smth) in enumerate(itertools.product(thresholds, tracts, regions, smths)):\n",
    "    # Path to the maps\n",
    "    regions_dir = op.join(\n",
    "        data_dir, \n",
    "        \"white-matter-atlas_thresholds\", \n",
    "        f\"cortexmap_binarize_smooth-surf-1_threshold-{threshold}_dilate-0\", \n",
    "        \"cortexmap\", \n",
    "        \"func\",\n",
    "    )\n",
    "    \n",
    "    # Read maps\n",
    "    map_lh = op.join(regions_dir, f\"lh.left{tract}_box_1mm_{region}_FiberEndpoint{smth}.func.gii\")\n",
    "    map_rh = op.join(regions_dir, f\"rh.right{tract}_box_1mm_{region}_FiberEndpoint{smth}.func.gii\")\n",
    "    map_arr_lh = nib.load(map_lh).agg_data()\n",
    "    map_arr_rh = nib.load(map_rh).agg_data()\n",
    "\n",
    "    # Remove medial wall\n",
    "    map_arr = _rm_medial_wall(\n",
    "        map_arr_lh,\n",
    "        map_arr_rh,\n",
    "        space=SPACE,\n",
    "        density=DENSITY,\n",
    "        neuromaps_dir=neuromaps_dir,\n",
    "    )\n",
    "\n",
    "    # Decode map\n",
    "    corrs_df = decode.transform([map_arr], method=\"correlation\")\n",
    "    filtered_df, filtered_features, filtered_frequencies = _decoding_filter(\n",
    "        corrs_df,\n",
    "        features,\n",
    "        classification,\n",
    "        freq_by_topic=frequencies,\n",
    "        class_by_topic=class_lst,\n",
    "    )\n",
    "    filtered_df.columns = [\"r\"]\n",
    "    separated_results[f\"{tract}_{region}{smth}_thr-{threshold}\"] = filtered_df.sort_values(by=\"r\", ascending=False)\n",
    "\n",
    "    # radar plot and corr values \n",
    "    corrs = filtered_df[\"r\"].to_numpy()\n",
    "    n_rows = min(len(corrs), 10)\n",
    "    print(n_rows)\n",
    "    if not np.any(np.isnan(corrs)) and corrs.size > 0: # Skip one of the regions of CST\n",
    "        # Radar plot\n",
    "        # plot_radar(\n",
    "        #     corrs, \n",
    "        #     filtered_features, \n",
    "        #     MODEL,\n",
    "        #     out_fig=op.join(sep_figures_dir_test, f\"{fig_i}-02_{tract}_{region}{smth}_thr-{threshold}_radar.png\"),\n",
    "        # )\n",
    "\n",
    "        # Sort features and correlations\n",
    "        corrs_plot = np.array(corrs)\n",
    "        sorted_indices = np.argsort(-corrs_plot)\n",
    "        corrs_plot = corrs_plot[sorted_indices]\n",
    "        feature_plot = np.array(filtered_features, dtype=object)[sorted_indices]\n",
    "\n",
    "        # Create df for a few tracts\n",
    "        radar_df = pd.DataFrame() \n",
    "        radar_df['r'] = corrs_plot\n",
    "        radar_df['terms'] = feature_plot\n",
    "        #radar_df.to_csv(tract + \"_\" + region + \"_\" + smth + \"_\" + threshold + \"_radar_plot_data.csv\")\n",
    "\n",
    "        # # Keep only topics and terms in radar plot\n",
    "        # n_top_terms = 3\n",
    "        # corrs_plot = corrs_plot[:n_rows]\n",
    "        # feature_plot = feature_plot[:n_rows]\n",
    "        # feature_plot = [\"--\".join(feature_plot[:n_top_terms]).replace(\" \", \"--\") for feature_plot in feature_plot]\n",
    "        # corrs_all = np.append(corrs_all, corrs_plot)\n",
    "        # features_all = np.append(features_all, feature_plot)\n",
    "        #fileName = np.append(fileName, np.full(n_rows, tract + \"_\" + region + \"_\" + smth))\n",
    "\n",
    "    # # Create df for all figures\n",
    "    # radar_df = pd.DataFrame() \n",
    "    # radar_df['file name'] = fileName\n",
    "    # radar_df['r'] = corrs_all\n",
    "    # radar_df['terms'] = features_all\n",
    "    # radar_df.to_csv('ILF_RAS_smooth_thr0_radar_plot_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ILF_LPI.smooth_1_thr-0':                                                r\n",
       " feature                                         \n",
       " 72_visual_process_fusiform gyrus        0.618054\n",
       " 183_visual_fixation_orientation         0.504462\n",
       " 5_motion_sts_psts                       0.470403\n",
       " 114_face_ffa_process                    0.437117\n",
       " 157_object_loc_image                    0.403368\n",
       " 192_stimuli_stimulus_process            0.373574\n",
       " 113_gaze_saccade_eye                    0.366811\n",
       " 85_reading_letter_orthographic          0.279264\n",
       " 59_categories_category_animal           0.276348\n",
       " 187_spatial_shape_visuospatial          0.271425\n",
       " 198_cue_cues_cued                       0.270381\n",
       " 169_scene_ppa_image                     0.248332\n",
       " 181_attention_attended_top              0.241749\n",
       " 37_hand_body_part                       0.234183\n",
       " 168_video_gesture_communication         0.225200\n",
       " 121_perceptual_perception_conscious     0.218379\n",
       " 2_picture_valence_arousal               0.211130\n",
       " 167_virtual_navigation_deception        0.196622\n",
       " 35_preference_sexual_bias               0.194723\n",
       " 47_expression_facial expression_facial  0.194230\n",
       " 102_novel_repetition_priming            0.168133\n",
       " 36_response_difference_greater          0.155942\n",
       " 39_target_search_trial                  0.149359\n",
       " 184_representation_concept_knowledge    0.138792\n",
       " 116_color_interference_stroop           0.135752\n",
       " 152_action_observation_mirror           0.134349\n",
       " 132_word_concrete_process               0.123006\n",
       " 118_prediction_coding_natural           0.116378\n",
       " 64_external_internal_identity           0.105465\n",
       " 143_task_one_performance                0.101780\n",
       " 38_encoding_memory_retrieval            0.100208\n",
       " 97_activity_related_increased           0.099973\n",
       " 21_image_function_brain                 0.099419\n",
       " 174_rule_shift_dimensional              0.099136\n",
       " 56_problem_arithmetic_subtraction       0.096871\n",
       " 180_writing_drawing_style               0.093285\n",
       " 26_verbal_creativity_intelligence       0.075595\n",
       " 7_load_difficult_demand                 0.066756\n",
       " 70_performance_accuracy_task            0.061461\n",
       " 199_naming_generation_production        0.052021\n",
       " 109_emotional_process_neural            0.051674\n",
       " 71_strategy_strategies_reasoning        0.036263\n",
       " 195_familiar_recollection_unfamiliar    0.035594\n",
       " 151_phonological_lexical_pseudoword     0.034803\n",
       " 62_semantic_meaning_related             0.029425\n",
       " 91_salience_salient_salience network    0.024161\n",
       " 142_game_intention_partner              0.020278\n",
       " 69_switch_switching_preparation         0.019346\n",
       " 115_stop_pre sma_coherence              0.009095\n",
       " 83_fear_threat_avoidance                0.007486}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "separated_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main code: (299881,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "# NOTES TO SELF\n",
    "sep_figures_dir = op.join(figures_dir, \"separated\")\n",
    "os.makedirs(sep_figures_dir, exist_ok=True)\n",
    "\n",
    "separated_results = {}\n",
    "fig_names = []\n",
    "tract = \"Arc\"\n",
    "regions = \"RAS\"\n",
    "smths = \".smooth_1\"\n",
    "thresholds = \"0\"\n",
    "\n",
    "regions_dir = op.join(\n",
    "        data_dir, \n",
    "        \"white-matter-atlas_thresholds\", \n",
    "        f\"cortexmap_binarize_smooth-surf-1_threshold-{thresholds}_dilate-0\", \n",
    "        \"cortexmap\", \n",
    "        \"func\",\n",
    ")\n",
    "\n",
    "# Read maps\n",
    "map_lh = op.join(regions_dir, f\"lh.left{tract}_box_1mm_{regions}_FiberEndpoint{smths}.func.gii\")\n",
    "map_rh = op.join(regions_dir, f\"rh.right{tract}_box_1mm_{regions}_FiberEndpoint{smths}.func.gii\")\n",
    "map_arr_lh = nib.load(map_lh).agg_data()\n",
    "map_arr_rh = nib.load(map_rh).agg_data()\n",
    "\n",
    "    # Remove medial wall\n",
    "map_arr = _rm_medial_wall(\n",
    "        map_arr_lh,\n",
    "        map_arr_rh,\n",
    "        space=SPACE,\n",
    "        density=DENSITY,\n",
    "        neuromaps_dir=neuromaps_dir,\n",
    ")\n",
    "\n",
    "print(\"main code:\" , map_arr.shape)\n",
    "    # Decode map\n",
    "corrs_df = decode.transform([map_arr], method=\"correlation\") \n",
    "#  DSECRIBE WHAT THIS DOES. I THINK IT DOES THIS. DO YOU THINK CODE AND DESCRIPTION MATCH? DO YOU THINK THIS IS APPROPRIATE ANALYSIS?\n",
    "# COSINE DISTANCE? \n",
    "# VERTEX CORRELATION? WHAT IS VERTEX ON BRAIN?\n",
    "\n",
    "\n",
    "filtered_df, filtered_features, filtered_frequencies = _decoding_filter(\n",
    "    corrs_df,\n",
    "    features,\n",
    "    classification,\n",
    "    freq_by_topic=frequencies,\n",
    "    class_by_topic=class_lst,\n",
    ")\n",
    "filtered_df.columns = [\"r\"]\n",
    "separated_results[f\"{tract}_{regions}{smths}_thr-{thresholds}\"] = filtered_df.sort_values(by=\"r\", ascending=False)\n",
    "\n",
    "# Visualize maps to decode\n",
    "# Visualize results\n",
    "corrs = filtered_df[\"r\"].to_numpy()\n",
    "features = filtered_features\n",
    "\n",
    "# Sort features and correlations\n",
    "corrs = np.array(corrs)\n",
    "sorted_indices = np.argsort(-corrs)\n",
    "corrs = corrs[sorted_indices]\n",
    "features = np.array(features, dtype=object)[sorted_indices]\n",
    "\n",
    "n_rows = min(len(corrs), 10)\n",
    "corrs = corrs[:n_rows]\n",
    "features = features[:n_rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(299881,)\n",
      "(163842,)\n",
      "(163842,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(map_arr.shape)\n",
    "print(map_arr_rh.shape)\n",
    "print(map_arr_lh.shape)\n",
    "\n",
    "N_VERTICES_PH = 32492\n",
    "map_arr_lh.shape[0] == N_VERTICES_PH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run decoder on each regions separate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "/home/sohmee/.local/share/virtualenvs/test-uar988OR/lib/python3.10/site-packages/numpy/lib/npyio.py:1393: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X = np.asarray(X)\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "/home/sohmee/.local/share/virtualenvs/test-uar988OR/lib/python3.10/site-packages/numpy/lib/npyio.py:1393: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X = np.asarray(X)\n",
      "/home/sohmee/.local/share/virtualenvs/test-uar988OR/lib/python3.10/site-packages/nimare/stats.py:109: RuntimeWarning: invalid value encountered in true_divide\n",
      "  rs = temp / (datass[1:] * datass[0])\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "/home/sohmee/.local/share/virtualenvs/test-uar988OR/lib/python3.10/site-packages/nimare/stats.py:109: RuntimeWarning: invalid value encountered in true_divide\n",
      "  rs = temp / (datass[1:] * datass[0])\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "/home/sohmee/.local/share/virtualenvs/test-uar988OR/lib/python3.10/site-packages/numpy/lib/npyio.py:1393: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X = np.asarray(X)\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "/home/sohmee/.local/share/virtualenvs/test-uar988OR/lib/python3.10/site-packages/numpy/lib/npyio.py:1393: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X = np.asarray(X)\n",
      "/home/sohmee/.local/share/virtualenvs/test-uar988OR/lib/python3.10/site-packages/nimare/stats.py:109: RuntimeWarning: invalid value encountered in true_divide\n",
      "  rs = temp / (datass[1:] * datass[0])\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "/home/sohmee/.local/share/virtualenvs/test-uar988OR/lib/python3.10/site-packages/nimare/stats.py:109: RuntimeWarning: invalid value encountered in true_divide\n",
      "  rs = temp / (datass[1:] * datass[0])\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "/home/sohmee/.local/share/virtualenvs/test-uar988OR/lib/python3.10/site-packages/numpy/lib/npyio.py:1393: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X = np.asarray(X)\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "/home/sohmee/.local/share/virtualenvs/test-uar988OR/lib/python3.10/site-packages/numpy/lib/npyio.py:1393: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X = np.asarray(X)\n",
      "/home/sohmee/.local/share/virtualenvs/test-uar988OR/lib/python3.10/site-packages/nimare/stats.py:109: RuntimeWarning: invalid value encountered in true_divide\n",
      "  rs = temp / (datass[1:] * datass[0])\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "/home/sohmee/.local/share/virtualenvs/test-uar988OR/lib/python3.10/site-packages/nimare/stats.py:109: RuntimeWarning: invalid value encountered in true_divide\n",
      "  rs = temp / (datass[1:] * datass[0])\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "sep_figures_dir = op.join(figures_dir, \"separated\")\n",
    "os.makedirs(sep_figures_dir, exist_ok=True)\n",
    "\n",
    "separated_results = {}\n",
    "for fig_i, (threshold, tract, region, smth) in enumerate(itertools.product(thresholds, tracts, regions, smths)):\n",
    "    # Path to the maps\n",
    "    regions_dir = op.join(\n",
    "        data_dir, \n",
    "        \"white-matter-atlas_thresholds\", \n",
    "        f\"cortexmap_binarize_smooth-surf-1_threshold-{threshold}_dilate-0\", \n",
    "        \"cortexmap\", \n",
    "        \"func\",\n",
    "    )\n",
    "    \n",
    "    # Read maps\n",
    "    map_lh = op.join(regions_dir, f\"lh.left{tract}_box_1mm_{region}_FiberEndpoint{smth}.func.gii\")\n",
    "    map_rh = op.join(regions_dir, f\"rh.right{tract}_box_1mm_{region}_FiberEndpoint{smth}.func.gii\")\n",
    "    map_arr_lh = nib.load(map_lh).agg_data()\n",
    "    map_arr_rh = nib.load(map_rh).agg_data()\n",
    "\n",
    "    # Remove medial wall\n",
    "    map_arr = _rm_medial_wall(\n",
    "        map_arr_lh,\n",
    "        map_arr_rh,\n",
    "        space=SPACE,\n",
    "        density=DENSITY,\n",
    "        neuromaps_dir=neuromaps_dir,\n",
    "    )\n",
    "\n",
    "    # Decode map\n",
    "    corrs_df = decode.transform([map_arr], method=\"correlation\")\n",
    "    filtered_df, filtered_features, filtered_frequencies = _decoding_filter(\n",
    "        corrs_df,\n",
    "        features,\n",
    "        classification,\n",
    "        freq_by_topic=frequencies,\n",
    "        class_by_topic=class_lst,\n",
    "    )\n",
    "    filtered_df.columns = [\"r\"]\n",
    "    separated_results[f\"{tract}_{region}{smth}_thr-{threshold}\"] = filtered_df.sort_values(by=\"r\", ascending=False)\n",
    "    np.savetxt(\"CST_features.csv\", filtered_features, fmt=\"%s\", delimiter = \",\")\n",
    "\n",
    "    # Visualize maps to decode\n",
    "    plot_surf_maps(\n",
    "        map_arr_lh, \n",
    "        map_arr_rh, \n",
    "        space=SPACE, \n",
    "        density=DENSITY, \n",
    "        cmap=\"YlOrRd\",\n",
    "        color_range=(0, 1),\n",
    "        title=f\"{TRACTS_DICT[tract]} {REGIONS_DICT[region]}\\n{SMTHS_DICT[smth]}. Threshold: {threshold}\",\n",
    "        data_dir=data_dir,\n",
    "        out_fig=op.join(sep_figures_dir, f\"{fig_i}-01_{tract}_{region}{smth}_thr-{threshold}_surf.png\"),\n",
    "    )\n",
    "\n",
    "    # Visualize results\n",
    "    corrs = filtered_df[\"r\"].to_numpy()\n",
    "\n",
    "    if not np.any(np.isnan(corrs)) and corrs.size > 0: # Skip one of the regions of CST\n",
    "        # Radar plot\n",
    "        plot_radar(\n",
    "            corrs, \n",
    "            filtered_features, \n",
    "            MODEL,\n",
    "            out_fig=op.join(sep_figures_dir, f\"{fig_i}-02_{tract}_{region}{smth}_thr-{threshold}_radar.png\"),\n",
    "        )\n",
    "        \n",
    "        # Word cloud plot\n",
    "        plot_cloud(\n",
    "            corrs, \n",
    "            filtered_features,\n",
    "            MODEL,\n",
    "            frequencies=filtered_frequencies,\n",
    "            out_fig=op.join(sep_figures_dir, f\"{fig_i}-03_{tract}_{region}{smth}_thr-{threshold}_wordcloud.png\"),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('CST_features.csv', 'w') as f:  # You will need 'wb' mode in Python 2.x\n",
    "    w = csv.DictWriter(f, separated_results.keys())\n",
    "    w.writeheader()\n",
    "    w.writerow(separated_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "662"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sep_figures_dir = op.join(figures_dir, \"separated\")\n",
    "os.makedirs(sep_figures_dir, exist_ok=True)\n",
    "\n",
    "separated_results = {}\n",
    "for tract in tracts:\n",
    "    for fig_i, (threshold, region, smth) in enumerate(itertools.product(thresholds, regions, smths)):\n",
    "        # Path to the maps\n",
    "        regions_dir = op.join(\n",
    "            data_dir, \n",
    "            \"white-matter-atlas_thresholds\", \n",
    "            f\"cortexmap_binarize_smooth-surf-1_threshold-{threshold}_dilate-0\", \n",
    "            \"cortexmap\", \n",
    "            \"func\",\n",
    "        )\n",
    "        \n",
    "        # Read maps\n",
    "        map_lh = op.join(regions_dir, f\"lh.left{tract}_box_1mm_{region}_FiberEndpoint{smth}.func.gii\")\n",
    "        map_rh = op.join(regions_dir, f\"rh.right{tract}_box_1mm_{region}_FiberEndpoint{smth}.func.gii\")\n",
    "        map_arr_lh = nib.load(map_lh).agg_data()\n",
    "        map_arr_rh = nib.load(map_rh).agg_data()\n",
    "\n",
    "        # Remove medial wall\n",
    "        map_arr = _rm_medial_wall(\n",
    "            map_arr_lh,\n",
    "            map_arr_rh,\n",
    "            space=SPACE,\n",
    "            density=DENSITY,\n",
    "            neuromaps_dir=neuromaps_dir,\n",
    "        )\n",
    "\n",
    "        # Decode map\n",
    "        corrs_df = decode.transform([map_arr], method=\"correlation\")\n",
    "        filtered_df, filtered_features, filtered_frequencies = _decoding_filter(\n",
    "            corrs_df,\n",
    "            features,\n",
    "            classification,\n",
    "            freq_by_topic=frequencies,\n",
    "            class_by_topic=class_lst,\n",
    "        )\n",
    "        filtered_df.columns = [\"r\"]\n",
    "        separated_results[f\"{tract}_{region}{smth}_thr-{threshold}\"] = filtered_df.sort_values(by=\"r\", ascending=False)\n",
    "\n",
    "        # Visualize maps to decode\n",
    "        plot_surf_maps(\n",
    "            map_arr_lh, \n",
    "            map_arr_rh, \n",
    "            space=SPACE, \n",
    "            density=DENSITY, \n",
    "            cmap=\"YlOrRd\",\n",
    "            color_range=(0, 1),\n",
    "            title=f\"{TRACTS_DICT[tract]} {REGIONS_DICT[region]}\\n{SMTHS_DICT[smth]}. Threshold: {threshold}\",\n",
    "            data_dir=data_dir,\n",
    "            out_fig=op.join(sep_figures_dir, f\"{fig_i}-01_{tract}_{region}{smth}_thr-{threshold}_surf.png\"),\n",
    "        )\n",
    "\n",
    "        # Visualize results\n",
    "        corrs = filtered_df[\"r\"].to_numpy()\n",
    "        if not np.any(np.isnan(corrs)) and corrs.size > 0: # Skip one of the regions of CST\n",
    "            # Radar plot\n",
    "            plot_radar(\n",
    "                corrs, \n",
    "                filtered_features, \n",
    "                MODEL,\n",
    "                out_fig=op.join(sep_figures_dir, f\"{fig_i}-02_{tract}_{region}{smth}_thr-{threshold}_radar.png\"),\n",
    "            )\n",
    "            \n",
    "            # Word cloud plot\n",
    "            plot_cloud(\n",
    "                corrs, \n",
    "                filtered_features,\n",
    "                MODEL,\n",
    "                frequencies=filtered_frequencies,\n",
    "                out_fig=op.join(sep_figures_dir, f\"{fig_i}-03_{tract}_{region}{smth}_thr-{threshold}_wordcloud.png\"),\n",
    "            )\n",
    "\n",
    "        del map_lh, map_rh, map_arr_lh, map_arr_rh, corrs_df, filtered_df, filtered_features, filtered_frequencies, corrs\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run decoder on combined regions for each tract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "/home/sohmee/.local/share/virtualenvs/test-uar988OR/lib/python3.10/site-packages/nimare/stats.py:109: RuntimeWarning: invalid value encountered in true_divide\n",
      "  rs = temp / (datass[1:] * datass[0])\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "115119"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "com_figures_dir = op.join(figures_dir, \"combined\")\n",
    "os.makedirs(com_figures_dir, exist_ok=True)\n",
    "\n",
    "combined_results = {}\n",
    "for fig_i, (threshold, tract, smth) in enumerate(itertools.product(thresholds, tracts, smths)):\n",
    "    # Path to the maps\n",
    "    regions_dir = op.join(\n",
    "        data_dir, \n",
    "        \"white-matter-atlas_thresholds\", \n",
    "        f\"cortexmap_binarize_smooth-surf-1_threshold-{threshold}_dilate-0\", \n",
    "        \"cortexmap\", \n",
    "        \"func\",\n",
    "    )\n",
    "    \n",
    "    # Read maps\n",
    "    map_lpi_lh = op.join(regions_dir, f\"lh.left{tract}_box_1mm_LPI_FiberEndpoint{smth}.func.gii\")\n",
    "    map_lpi_rh = op.join(regions_dir, f\"rh.right{tract}_box_1mm_LPI_FiberEndpoint{smth}.func.gii\")\n",
    "    map_ras_lh = op.join(regions_dir, f\"lh.left{tract}_box_1mm_RAS_FiberEndpoint{smth}.func.gii\")\n",
    "    map_ras_rh = op.join(regions_dir, f\"rh.right{tract}_box_1mm_RAS_FiberEndpoint{smth}.func.gii\")\n",
    "    \n",
    "    map_lpi_arr_lh = nib.load(map_lpi_lh).agg_data()\n",
    "    map_lpi_arr_rh = nib.load(map_lpi_rh).agg_data()\n",
    "    map_ras_arr_lh = nib.load(map_ras_lh).agg_data()\n",
    "    map_ras_arr_rh = nib.load(map_ras_rh).agg_data()\n",
    "\n",
    "    # Combined regions for each tract\n",
    "    map_arr_lh = np.maximum(map_lpi_arr_lh, map_ras_arr_lh) # Take the maximum to address overlap\n",
    "    map_arr_rh = np.maximum(map_lpi_arr_rh, map_ras_arr_rh) # Take the maximum to address overlap\n",
    "    \n",
    "    # Remove medial wall\n",
    "    map_arr = _rm_medial_wall(\n",
    "        map_arr_lh,\n",
    "        map_arr_rh,\n",
    "        space=SPACE,\n",
    "        density=DENSITY,\n",
    "        neuromaps_dir=neuromaps_dir,\n",
    "    )\n",
    "\n",
    "    # Decode map\n",
    "    corrs_df = decode.transform([map_arr], method=\"correlation\")\n",
    "    filtered_df, filtered_features, filtered_frequencies = _decoding_filter(\n",
    "        corrs_df,\n",
    "        features,\n",
    "        classification,\n",
    "        freq_by_topic=frequencies,\n",
    "        class_by_topic=class_lst,\n",
    "    )\n",
    "\n",
    "    filtered_df.columns = [\"r\"]\n",
    "    combined_results[f\"{tract}{smth}_thr-{threshold}\"] = filtered_df.sort_values(by=\"r\", ascending=False)\n",
    "\n",
    "    # Visualize maps to decode\n",
    "    surf_fig = plot_surf_maps(\n",
    "        map_arr_lh, \n",
    "        map_arr_rh, \n",
    "        space=SPACE, \n",
    "        density=DENSITY, \n",
    "        cmap=\"YlOrRd\",\n",
    "        color_range=(0, 1),\n",
    "        title=f\"{TRACTS_DICT[tract]} LPI+RAS\\n{SMTHS_DICT[smth]}. Threshold: {threshold}\",\n",
    "        data_dir=data_dir,\n",
    "        out_fig=op.join(com_figures_dir, f\"{fig_i}-01_{tract}_LPI+RAS{smth}_thr-{threshold}_surf.png\"),\n",
    "    )\n",
    "\n",
    "    # Visualize results\n",
    "    corrs = filtered_df[\"r\"].to_numpy()\n",
    "    if not np.any(np.isnan(corrs)) and corrs.size > 0: # Skip one of the regions of CST\n",
    "        # Radar plot\n",
    "        plot_radar(\n",
    "            corrs, \n",
    "            filtered_features, \n",
    "            MODEL,\n",
    "            out_fig=op.join(com_figures_dir, f\"{fig_i}-02_{tract}_LPI+RAS{smth}_thr-{threshold}_radar.png\"),\n",
    "        )\n",
    "\n",
    "        # Word cloud plot\n",
    "        plot_cloud(\n",
    "            corrs, \n",
    "            filtered_features,\n",
    "            MODEL,\n",
    "            frequencies=filtered_frequencies,\n",
    "            out_fig=op.join(com_figures_dir, f\"{fig_i}-03_{tract}_LPI+RAS{smth}_thr-{threshold}_wordcloud.png\"),\n",
    "        )\n",
    "    \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_width, comb_hight = 25, 13\n",
    "sep_width, sep_hight = 25, 25\n",
    "\n",
    "n_comb_rows, n_comb_cols = 3, 6\n",
    "n_sep_rows, n_sep_cols = 6, 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 6 is out of bounds for axis 0 with size 6",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m wordcloud_plt \u001b[38;5;241m=\u001b[39m op\u001b[38;5;241m.\u001b[39mjoin(sep_figures_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfig_i\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-03_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtract\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mregion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msmth\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_thr-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mthreshold\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_wordcloud.png\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m img_i, img_file \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m([surf_plt, radar_plt, wordcloud_plt]):\n\u001b[0;32m---> 15\u001b[0m     ax \u001b[38;5;241m=\u001b[39m fig\u001b[38;5;241m.\u001b[39madd_subplot(\u001b[43mgs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrc_i\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mreg_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msmth_i\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mimg_i\u001b[49m\u001b[43m]\u001b[49m, aspect\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mequal\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m op\u001b[38;5;241m.\u001b[39mexists(img_file):\n\u001b[1;32m     17\u001b[0m         img \u001b[38;5;241m=\u001b[39m mpimg\u001b[38;5;241m.\u001b[39mimread(img_file)    \n",
      "File \u001b[0;32m~/.local/share/virtualenvs/test-uar988OR/lib/python3.10/site-packages/matplotlib/gridspec.py:257\u001b[0m, in \u001b[0;36mGridSpecBase.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    255\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized subplot spec\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    256\u001b[0m     num1, num2 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mravel_multi_index(\n\u001b[0;32m--> 257\u001b[0m         [\u001b[43m_normalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m, _normalize(k2, ncols, \u001b[38;5;241m1\u001b[39m)],\n\u001b[1;32m    258\u001b[0m         (nrows, ncols))\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Single key\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     num1, num2 \u001b[38;5;241m=\u001b[39m _normalize(key, nrows \u001b[38;5;241m*\u001b[39m ncols, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/test-uar988OR/lib/python3.10/site-packages/matplotlib/gridspec.py:245\u001b[0m, in \u001b[0;36mGridSpecBase.__getitem__.<locals>._normalize\u001b[0;34m(key, size, axis)\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m key, key\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 245\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex \u001b[39m\u001b[38;5;132;01m{\u001b[39;00morig_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is out of bounds for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maxis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msize\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# flat index\u001b[39;00m\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex \u001b[39m\u001b[38;5;132;01m{\u001b[39;00morig_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is out of bounds for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    249\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGridSpec with size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msize\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 6 is out of bounds for axis 0 with size 6"
     ]
    }
   ],
   "source": [
    "fig_i = 0\n",
    "for thr_i, threshold in enumerate(thresholds):\n",
    "    fig = plt.figure(figsize=(sep_width, sep_hight))\n",
    "    fig.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=0.1, hspace=0.1)\n",
    "    gs = GridSpec(nrows=n_sep_rows, ncols=n_sep_cols, figure=fig)\n",
    "\n",
    "    for trc_i, tract in enumerate(tracts):\n",
    "        for reg_i, region in enumerate(regions):\n",
    "            for smth_i, smth in enumerate(smths):\n",
    "                surf_plt = op.join(sep_figures_dir, f\"{fig_i}-01_{tract}_{region}{smth}_thr-{threshold}_surf.png\")\n",
    "                radar_plt = op.join(sep_figures_dir, f\"{fig_i}-02_{tract}_{region}{smth}_thr-{threshold}_radar.png\")\n",
    "                wordcloud_plt = op.join(sep_figures_dir, f\"{fig_i}-03_{tract}_{region}{smth}_thr-{threshold}_wordcloud.png\")\n",
    "\n",
    "                for img_i, img_file in enumerate([surf_plt, radar_plt, wordcloud_plt]):\n",
    "                    ax = fig.add_subplot(gs[trc_i*2 + reg_i, smth_i*3 + img_i], aspect=\"equal\")\n",
    "                    if op.exists(img_file):\n",
    "                        img = mpimg.imread(img_file)    \n",
    "                        ax.imshow(img)\n",
    "\n",
    "                    ax.set_axis_off()\n",
    "\n",
    "                fig_i += 1\n",
    "\n",
    "        out_file = op.join(figures_dir, f\"results-separated_thr-{float(threshold):.2f}.png\")\n",
    "        fig.savefig(out_file, bbox_inches=\"tight\", dpi=300)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_i = 0\n",
    "for thr_i, threshold in enumerate(thresholds):\n",
    "    fig = plt.figure(figsize=(comb_width, comb_hight))\n",
    "    fig.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=0.1, hspace=0.1)\n",
    "    gs = GridSpec(nrows=n_comb_rows, ncols=n_comb_cols, figure=fig)\n",
    "\n",
    "    for trc_i, tract in enumerate(tracts):\n",
    "        for smth_i, smth in enumerate(smths):\n",
    "\n",
    "            surf_plt = op.join(com_figures_dir, f\"{fig_i}-01_{tract}_LPI+RAS{smth}_thr-{threshold}_surf.png\")\n",
    "            radar_plt = op.join(com_figures_dir, f\"{fig_i}-02_{tract}_LPI+RAS{smth}_thr-{threshold}_radar.png\")\n",
    "            wordcloud_plt = op.join(com_figures_dir, f\"{fig_i}-03_{tract}_LPI+RAS{smth}_thr-{threshold}_wordcloud.png\")\n",
    "            \n",
    "            for img_i, img_file in enumerate([surf_plt, radar_plt, wordcloud_plt]):\n",
    "                ax = fig.add_subplot(gs[trc_i, smth_i*3 + img_i], aspect=\"equal\")\n",
    "                if op.exists(img_file):\n",
    "                    img = mpimg.imread(img_file)    \n",
    "                    ax.imshow(img)\n",
    "                \n",
    "                ax.set_axis_off()\n",
    "\n",
    "            fig_i += 1\n",
    "\n",
    "    out_file = op.join(figures_dir, f\"results-combined_thr-{float(threshold):.2f}.png\")\n",
    "    fig.savefig(out_file, bbox_inches=\"tight\", dpi=300)\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gradec_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
