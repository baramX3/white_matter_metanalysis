{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os.path as op\n",
    "import os\n",
    "\n",
    "from gradec.decode import LDADecoder\n",
    "from gradec.utils import _rm_medial_wall, _decoding_filter\n",
    "from gradec.plot import plot_surf_maps, plot_radar, plot_cloud\n",
    "from gradec.fetcher import _fetch_features, _fetch_frequencies, _fetch_classification\n",
    "import nibabel as nib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define space, density and paths to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPACE, DENSITY = \"fsaverage\", \"164k\"\n",
    "DSET, MODEL = \"neuroquery\", \"lda\"\n",
    "\n",
    "data_dir = op.join(\".\", \"data\")\n",
    "neuromaps_dir = op.join(data_dir, \"neuromaps\")\n",
    "figures_dir = op.join(data_dir, \"figures\")\n",
    "\n",
    "# List of possible combinations of tracts, regions and smoothing\n",
    "tracts = [\"Arc\", \"SLF1And2\", \"CST\"]\n",
    "regions = [\"RAS\", \"LPI\"]\n",
    "smths = [\"\", \".smooth_1\"]\n",
    "thresholds = [\"0\", \"0.15\", \"0.25\"]\n",
    "\n",
    "# Dictionaries for the title of the figures\n",
    "TRACTS_DICT = {\n",
    "    \"Arc\": \"Arcuate\",\n",
    "    \"CST\": \"Corticospinal\",\n",
    "    \"SLF1And2\": \"SLF 1 & 2\",\n",
    "}\n",
    "REGIONS_DICT = {\n",
    "    \"LPI\": \"Left-Posterior-Inferior\",\n",
    "    \"RAS\": \"Right-Anterior-Superior\",\n",
    "}\n",
    "SMTHS_DICT = {\n",
    "    \"\": \"Unsmoothed\",\n",
    "    \".smooth_1\": \"Smoothed\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and LDA-based decoder on NeuroQuery detabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode = LDADecoder(space=SPACE, density=DENSITY, calc_pvals=False, data_dir=data_dir)\n",
    "decode.fit(DSET)\n",
    "\n",
    "# Load features for visualization\n",
    "features = _fetch_features(DSET, MODEL, data_dir=data_dir)\n",
    "frequencies = _fetch_frequencies(DSET, MODEL, data_dir=data_dir)\n",
    "classification, class_lst = _fetch_classification(DSET, MODEL, data_dir=data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run decoder on each regions separate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sep_figures_dir = op.join(figures_dir, \"separated\")\n",
    "os.makedirs(sep_figures_dir, exist_ok=True)\n",
    "\n",
    "separated_results = {}\n",
    "for fig_i, (threshold, tract, region, smth) in enumerate(itertools.product(thresholds, tracts, regions, smths)):\n",
    "    # Path to the maps\n",
    "    regions_dir = op.join(\n",
    "        data_dir, \n",
    "        \"white-matter-atlas_thresholds\", \n",
    "        f\"cortexmap_binarize_smooth-surf-1_threshold-{threshold}_dilate-0\", \n",
    "        \"cortexmap\", \n",
    "        \"func\",\n",
    "    )\n",
    "    \n",
    "    # Read maps\n",
    "    map_lh = op.join(regions_dir, f\"lh.left{tract}_box_1mm_{region}_FiberEndpoint{smth}.func.gii\")\n",
    "    map_rh = op.join(regions_dir, f\"rh.right{tract}_box_1mm_{region}_FiberEndpoint{smth}.func.gii\")\n",
    "    map_arr_lh = nib.load(map_lh).agg_data()\n",
    "    map_arr_rh = nib.load(map_rh).agg_data()\n",
    "\n",
    "    # Remove medial wall\n",
    "    map_arr = _rm_medial_wall(\n",
    "        map_arr_lh,\n",
    "        map_arr_rh,\n",
    "        space=SPACE,\n",
    "        density=DENSITY,\n",
    "        neuromaps_dir=neuromaps_dir,\n",
    "    )\n",
    "\n",
    "    # Decode map\n",
    "    corrs_df = decode.transform([map_arr], method=\"correlation\")\n",
    "    filtered_df, filtered_features, filtered_frequencies = _decoding_filter(\n",
    "        corrs_df,\n",
    "        features,\n",
    "        classification,\n",
    "        freq_by_topic=frequencies,\n",
    "        class_by_topic=class_lst,\n",
    "    )\n",
    "    filtered_df.columns = [\"r\"]\n",
    "    separated_results[f\"{tract}_{region}{smth}_thr-{threshold}\"] = filtered_df.sort_values(by=\"r\", ascending=False)\n",
    "\n",
    "    # Visualize maps to decode\n",
    "    plot_surf_maps(\n",
    "        map_arr_lh, \n",
    "        map_arr_rh, \n",
    "        space=SPACE, \n",
    "        density=DENSITY, \n",
    "        cmap=\"YlOrRd\",\n",
    "        color_range=(0, 1),\n",
    "        title=f\"{TRACTS_DICT[tract]} {REGIONS_DICT[region]}\\n{SMTHS_DICT[smth]}. Threshold: {threshold}\",\n",
    "        data_dir=data_dir,\n",
    "        out_fig=op.join(sep_figures_dir, f\"{fig_i}-01_{tract}_{region}{smth}_thr-{threshold}_surf.png\"),\n",
    "    )\n",
    "\n",
    "    # Visualize results\n",
    "    corrs = filtered_df[\"r\"].to_numpy()\n",
    "    if not np.any(np.isnan(corrs)) and corrs.size > 0: # Skip one of the regions of CST\n",
    "        # Radar plot\n",
    "        plot_radar(\n",
    "            corrs, \n",
    "            filtered_features, \n",
    "            MODEL,\n",
    "            out_fig=op.join(sep_figures_dir, f\"{fig_i}-02_{tract}_{region}{smth}_thr-{threshold}_radar.png\"),\n",
    "        )\n",
    "        \n",
    "        # Word cloud plot\n",
    "        plot_cloud(\n",
    "            corrs, \n",
    "            filtered_features,\n",
    "            MODEL,\n",
    "            frequencies=filtered_frequencies,\n",
    "            out_fig=op.join(sep_figures_dir, f\"{fig_i}-03_{tract}_{region}{smth}_thr-{threshold}_wordcloud.png\"),\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run decoder on combined regions for each tract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_figures_dir = op.join(figures_dir, \"combined\")\n",
    "os.makedirs(com_figures_dir, exist_ok=True)\n",
    "\n",
    "combined_results = {}\n",
    "for fig_i, (threshold, tract, smth) in enumerate(itertools.product(thresholds, tracts, smths)):\n",
    "    # Path to the maps\n",
    "    regions_dir = op.join(\n",
    "        data_dir, \n",
    "        \"white-matter-atlas_thresholds\", \n",
    "        f\"cortexmap_binarize_smooth-surf-1_threshold-{threshold}_dilate-0\", \n",
    "        \"cortexmap\", \n",
    "        \"func\",\n",
    "    )\n",
    "    \n",
    "    # Read maps\n",
    "    map_lpi_lh = op.join(regions_dir, f\"lh.left{tract}_box_1mm_LPI_FiberEndpoint{smth}.func.gii\")\n",
    "    map_lpi_rh = op.join(regions_dir, f\"rh.right{tract}_box_1mm_LPI_FiberEndpoint{smth}.func.gii\")\n",
    "    map_ras_lh = op.join(regions_dir, f\"lh.left{tract}_box_1mm_RAS_FiberEndpoint{smth}.func.gii\")\n",
    "    map_ras_rh = op.join(regions_dir, f\"rh.right{tract}_box_1mm_RAS_FiberEndpoint{smth}.func.gii\")\n",
    "    \n",
    "    map_lpi_arr_lh = nib.load(map_lpi_lh).agg_data()\n",
    "    map_lpi_arr_rh = nib.load(map_lpi_rh).agg_data()\n",
    "    map_ras_arr_lh = nib.load(map_ras_lh).agg_data()\n",
    "    map_ras_arr_rh = nib.load(map_ras_rh).agg_data()\n",
    "\n",
    "    # Combined regions for each tract\n",
    "    map_arr_lh = np.maximum(map_lpi_arr_lh, map_ras_arr_lh) # Take the maximum to address overlap\n",
    "    map_arr_rh = np.maximum(map_lpi_arr_rh, map_ras_arr_rh) # Take the maximum to address overlap\n",
    "    \n",
    "    # Remove medial wall\n",
    "    map_arr = _rm_medial_wall(\n",
    "        map_arr_lh,\n",
    "        map_arr_rh,\n",
    "        space=SPACE,\n",
    "        density=DENSITY,\n",
    "        neuromaps_dir=neuromaps_dir,\n",
    "    )\n",
    "\n",
    "    # Decode map\n",
    "    corrs_df = decode.transform([map_arr], method=\"correlation\")\n",
    "    filtered_df, filtered_features, filtered_frequencies = _decoding_filter(\n",
    "        corrs_df,\n",
    "        features,\n",
    "        classification,\n",
    "        freq_by_topic=frequencies,\n",
    "        class_by_topic=class_lst,\n",
    "    )\n",
    "\n",
    "    filtered_df.columns = [\"r\"]\n",
    "    combined_results[f\"{tract}{smth}_thr-{threshold}\"] = filtered_df.sort_values(by=\"r\", ascending=False)\n",
    "\n",
    "    # Visualize maps to decode\n",
    "    surf_fig = plot_surf_maps(\n",
    "        map_arr_lh, \n",
    "        map_arr_rh, \n",
    "        space=SPACE, \n",
    "        density=DENSITY, \n",
    "        cmap=\"YlOrRd\",\n",
    "        color_range=(0, 1),\n",
    "        title=f\"{TRACTS_DICT[tract]} LPI+RAS\\n{SMTHS_DICT[smth]}. Threshold: {threshold}\",\n",
    "        data_dir=data_dir,\n",
    "        out_fig=op.join(com_figures_dir, f\"{fig_i}-01_{tract}_LPI+RAS{smth}_thr-{threshold}_surf.png\"),\n",
    "    )\n",
    "\n",
    "    # Visualize results\n",
    "    corrs = filtered_df[\"r\"].to_numpy()\n",
    "    if not np.any(np.isnan(corrs)) and corrs.size > 0: # Skip one of the regions of CST\n",
    "        # Radar plot\n",
    "        plot_radar(\n",
    "            corrs, \n",
    "            filtered_features, \n",
    "            MODEL,\n",
    "            out_fig=op.join(com_figures_dir, f\"{fig_i}-02_{tract}_LPI+RAS{smth}_thr-{threshold}_radar.png\"),\n",
    "        )\n",
    "\n",
    "        # Word cloud plot\n",
    "        plot_cloud(\n",
    "            corrs, \n",
    "            filtered_features,\n",
    "            MODEL,\n",
    "            frequencies=filtered_frequencies,\n",
    "            out_fig=op.join(com_figures_dir, f\"{fig_i}-03_{tract}_LPI+RAS{smth}_thr-{threshold}_wordcloud.png\"),\n",
    "        )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_width, comb_hight = 25, 13\n",
    "sep_width, sep_hight = 25, 25\n",
    "\n",
    "n_comb_rows, n_comb_cols = 3, 6\n",
    "n_sep_rows, n_sep_cols = 6, 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_i = 0\n",
    "for thr_i, threshold in enumerate(thresholds):\n",
    "    fig = plt.figure(figsize=(sep_width, sep_hight))\n",
    "    fig.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=0.1, hspace=0.1)\n",
    "    gs = GridSpec(nrows=n_sep_rows, ncols=n_sep_cols, figure=fig)\n",
    "\n",
    "    for trc_i, tract in enumerate(tracts):\n",
    "        for reg_i, region in enumerate(regions):\n",
    "            for smth_i, smth in enumerate(smths):\n",
    "                surf_plt = op.join(sep_figures_dir, f\"{fig_i}-01_{tract}_{region}{smth}_thr-{threshold}_surf.png\")\n",
    "                radar_plt = op.join(sep_figures_dir, f\"{fig_i}-02_{tract}_{region}{smth}_thr-{threshold}_radar.png\")\n",
    "                wordcloud_plt = op.join(sep_figures_dir, f\"{fig_i}-03_{tract}_{region}{smth}_thr-{threshold}_wordcloud.png\")\n",
    "\n",
    "                for img_i, img_file in enumerate([surf_plt, radar_plt, wordcloud_plt]):\n",
    "                    ax = fig.add_subplot(gs[trc_i*2 + reg_i, smth_i*3 + img_i], aspect=\"equal\")\n",
    "                    if op.exists(img_file):\n",
    "                        img = mpimg.imread(img_file)    \n",
    "                        ax.imshow(img)\n",
    "\n",
    "                    ax.set_axis_off()\n",
    "\n",
    "                fig_i += 1\n",
    "\n",
    "        out_file = op.join(figures_dir, f\"results-separated_thr-{float(threshold):.2f}.png\")\n",
    "        fig.savefig(out_file, bbox_inches=\"tight\", dpi=300)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_i = 0\n",
    "for thr_i, threshold in enumerate(thresholds):\n",
    "    fig = plt.figure(figsize=(comb_width, comb_hight))\n",
    "    fig.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=0.1, hspace=0.1)\n",
    "    gs = GridSpec(nrows=n_comb_rows, ncols=n_comb_cols, figure=fig)\n",
    "\n",
    "    for trc_i, tract in enumerate(tracts):\n",
    "        for smth_i, smth in enumerate(smths):\n",
    "\n",
    "            surf_plt = op.join(com_figures_dir, f\"{fig_i}-01_{tract}_LPI+RAS{smth}_thr-{threshold}_surf.png\")\n",
    "            radar_plt = op.join(com_figures_dir, f\"{fig_i}-02_{tract}_LPI+RAS{smth}_thr-{threshold}_radar.png\")\n",
    "            wordcloud_plt = op.join(com_figures_dir, f\"{fig_i}-03_{tract}_LPI+RAS{smth}_thr-{threshold}_wordcloud.png\")\n",
    "            \n",
    "            for img_i, img_file in enumerate([surf_plt, radar_plt, wordcloud_plt]):\n",
    "                ax = fig.add_subplot(gs[trc_i, smth_i*3 + img_i], aspect=\"equal\")\n",
    "                if op.exists(img_file):\n",
    "                    img = mpimg.imread(img_file)    \n",
    "                    ax.imshow(img)\n",
    "                \n",
    "                ax.set_axis_off()\n",
    "\n",
    "            fig_i += 1\n",
    "\n",
    "    out_file = op.join(figures_dir, f\"results-combined_thr-{float(threshold):.2f}.png\")\n",
    "    fig.savefig(out_file, bbox_inches=\"tight\", dpi=300)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gradec_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
